#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®è´¨é‡å¯è§†åŒ–å·¥å…·
ç”¨äºå¯¹æ¯”è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„è¯¯å·®åˆ†å¸ƒã€å›¾åƒè´¨é‡ç­‰
å¸®åŠ©è¯Šæ–­trainé™valä¸é™çš„é—®é¢˜
"""
import numpy as np
import matplotlib.pyplot as plt
import argparse
from pathlib import Path

def plot_distributions(ax, data, name):
    """ç»˜åˆ¶è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾"""
    e2_total = data['e2x'] + data['e2y']
    err_total = np.sqrt(e2_total)
    
    # ç»Ÿè®¡ä¿¡æ¯
    mean_err = np.mean(err_total)
    median_err = np.median(err_total)
    p95_err = np.percentile(err_total, 95)
    
    ax.hist(err_total, bins=100, range=(0, 20), density=True, alpha=0.7, 
            label=f'{name.upper()} (mean={mean_err:.2f}, p95={p95_err:.2f})')
    ax.set_title(f'Reprojection Error Distribution - {name.capitalize()} Set')
    ax.set_xlabel('Reprojection Error (pixels)')
    ax.set_ylabel('Density')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
    stats_text = f'Mean: {mean_err:.2f}px\nMedian: {median_err:.2f}px\n95th: {p95_err:.2f}px'
    ax.text(0.98, 0.98, stats_text, transform=ax.transAxes, 
            verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

def plot_patches(ax, data, name, indices):
    """ç»˜åˆ¶æ ·æœ¬å›¾åƒå—"""
    patches = data['I0'][indices, 0]  # æ˜¾ç¤ºç¬¬ä¸€å¸§çš„patch
    n = len(indices)
    for i in range(n):
        ax[i].imshow(patches[i], cmap='gray', vmin=0, vmax=1)
        ax[i].set_xticks([])
        ax[i].set_yticks([])
        if i == 0:
            ax[i].set_ylabel(f'{name.upper()}', fontsize=10, fontweight='bold')

def plot_geom_features(ax, data, name):
    """ç»˜åˆ¶å‡ ä½•ç‰¹å¾åˆ†å¸ƒï¼ˆå‰4ç»´ï¼šå½’ä¸€åŒ–åæ ‡ï¼‰"""
    geom = data['geom']
    
    # åªæ˜¾ç¤ºå‰4ç»´ï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰
    for i in range(min(4, geom.shape[1])):
        ax.hist(geom[:, i], bins=50, alpha=0.5, label=f'dim {i}')
    
    ax.set_title(f'Geometric Features (coords) - {name.capitalize()}')
    ax.set_xlabel('Normalized Value')
    ax.set_ylabel('Count')
    ax.legend()
    ax.grid(True, alpha=0.3)

def plot_gradient_features(ax, data, name):
    """ç»˜åˆ¶æ¢¯åº¦ç‰¹å¾åˆ†å¸ƒï¼ˆç¬¬5-6ç»´ï¼‰"""
    geom = data['geom']
    
    if geom.shape[1] >= 6:
        g0 = geom[:, 4]  # gradient at frame 0
        g2 = geom[:, 5]  # gradient at frame 2
        
        ax.hist(g0, bins=50, alpha=0.6, label='g0 (frame 0)', range=(0, 100))
        ax.hist(g2, bins=50, alpha=0.6, label='g2 (frame 2)', range=(0, 100))
        
        ax.set_title(f'Gradient Magnitude - {name.capitalize()}')
        ax.set_xlabel('Gradient Value')
        ax.set_ylabel('Count')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # ç»Ÿè®¡ä½æ¢¯åº¦æ ·æœ¬æ¯”ä¾‹
        low_grad_ratio = np.mean((g0 < 10) | (g2 < 10))
        ax.text(0.98, 0.98, f'Low gradient (<10): {low_grad_ratio*100:.1f}%', 
                transform=ax.transAxes, verticalalignment='top', horizontalalignment='right',
                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))
    else:
        ax.text(0.5, 0.5, 'No gradient features\n(geom_dim < 6)', 
                ha='center', va='center', transform=ax.transAxes)
        ax.set_title(f'Gradient Features - {name.capitalize()}')

def main():
    parser = argparse.ArgumentParser(description="Compare train and validation NPZ data quality.")
    parser.add_argument('--train_npz', type=str, required=True, help='Path to train NPZ file')
    parser.add_argument('--val_npz', type=str, required=True, help='Path to validation NPZ file')
    parser.add_argument('--out', type=str, default='data_quality_comparison.png', 
                       help='Output figure path')
    args = parser.parse_args()

    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®è´¨é‡å¯è§†åŒ–å·¥å…·")
    print("="*60)
    
    print(f"\n[1/3] åŠ è½½æ•°æ®...")
    train_data = np.load(args.train_npz, allow_pickle=True)
    val_data = np.load(args.val_npz, allow_pickle=True)
    
    print(f"  è®­ç»ƒé›†: {len(train_data['I0'])} æ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_data['I0'])} æ ·æœ¬")
    print(f"  å‡ ä½•ç‰¹å¾ç»´åº¦: {train_data['geom'].shape[1]}")
    
    # æ‰“å°å…ƒæ•°æ®
    if 'meta' in train_data:
        train_meta = train_data['meta'].item() if isinstance(train_data['meta'], np.ndarray) else train_data['meta']
        print(f"\n  è®­ç»ƒé›†åºåˆ—: {train_meta.get('seqs', 'N/A')}")
    if 'meta' in val_data:
        val_meta = val_data['meta'].item() if isinstance(val_data['meta'], np.ndarray) else val_data['meta']
        print(f"  éªŒè¯é›†åºåˆ—: {val_meta.get('seqs', 'N/A')}")
    
    print(f"\n[2/3] ç”Ÿæˆå¯è§†åŒ–...")
    
    # åˆ›å»ºå›¾å½¢
    fig = plt.figure(figsize=(16, 12))
    gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)
    
    # ç¬¬ä¸€è¡Œï¼šè¯¯å·®åˆ†å¸ƒå¯¹æ¯”
    ax1 = fig.add_subplot(gs[0, :2])
    plot_distributions(ax1, train_data, 'train')
    ax2 = fig.add_subplot(gs[0, 2:])
    plot_distributions(ax2, val_data, 'val')
    
    # ç¬¬äºŒè¡Œï¼šå‡ ä½•ç‰¹å¾åˆ†å¸ƒ
    ax3 = fig.add_subplot(gs[1, :2])
    plot_geom_features(ax3, train_data, 'train')
    ax4 = fig.add_subplot(gs[1, 2:])
    plot_geom_features(ax4, val_data, 'val')
    
    # ç¬¬ä¸‰è¡Œï¼šæ¢¯åº¦ç‰¹å¾åˆ†å¸ƒ
    ax5 = fig.add_subplot(gs[2, :2])
    plot_gradient_features(ax5, train_data, 'train')
    ax6 = fig.add_subplot(gs[2, 2:])
    plot_gradient_features(ax6, val_data, 'val')
    
    # ç¬¬å››è¡Œï¼šæ ·æœ¬å›¾åƒå—
    print("  éšæœºé€‰æ‹©æ ·æœ¬è¿›è¡Œå¯è§†åŒ–...")
    rng = np.random.default_rng(0)
    train_indices = rng.choice(len(train_data['I0']), 4, replace=False)
    val_indices = rng.choice(len(val_data['I0']), 4, replace=False)
    
    train_patch_axes = [fig.add_subplot(gs[3, i]) for i in range(4)]
    plot_patches(train_patch_axes, train_data, 'train', train_indices)
    
    val_patch_axes = [fig.add_subplot(gs[3, i]) for i in range(4)]
    plot_patches(val_patch_axes, val_data, 'val', val_indices)
    
    # æ·»åŠ æ€»æ ‡é¢˜
    fig.suptitle('Training vs Validation Data Quality Comparison', 
                fontsize=16, fontweight='bold', y=0.995)
    
    # ä¿å­˜å›¾åƒ
    out_path = Path(args.out)
    plt.savefig(out_path, dpi=150, bbox_inches='tight')
    
    print(f"\n[3/3] ä¿å­˜å®Œæˆ")
    print(f"  âœ… å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {out_path.absolute()}")
    
    # è®¡ç®—å¹¶æ‰“å°å…³é”®å·®å¼‚
    print(f"\n" + "="*60)
    print("ğŸ“ˆ å…³é”®å·®å¼‚åˆ†æ")
    print("="*60)
    
    train_err = np.sqrt(train_data['e2x'] + train_data['e2y'])
    val_err = np.sqrt(val_data['e2x'] + val_data['e2y'])
    
    print(f"\nè¯¯å·®ç»Ÿè®¡:")
    print(f"  è®­ç»ƒé›† - å‡å€¼: {np.mean(train_err):.2f}px, ä¸­ä½æ•°: {np.median(train_err):.2f}px")
    print(f"  éªŒè¯é›† - å‡å€¼: {np.mean(val_err):.2f}px, ä¸­ä½æ•°: {np.median(val_err):.2f}px")
    print(f"  å·®å¼‚ç‡: {(np.mean(val_err)/np.mean(train_err)-1)*100:+.1f}%")
    
    if train_data['geom'].shape[1] >= 6:
        train_grad = train_data['geom'][:, 4:6].mean()
        val_grad = val_data['geom'][:, 4:6].mean()
        print(f"\næ¢¯åº¦ç»Ÿè®¡:")
        print(f"  è®­ç»ƒé›†å¹³å‡æ¢¯åº¦: {train_grad:.2f}")
        print(f"  éªŒè¯é›†å¹³å‡æ¢¯åº¦: {val_grad:.2f}")
        print(f"  å·®å¼‚ç‡: {(val_grad/train_grad-1)*100:+.1f}%")
    
    if np.mean(val_err) > np.mean(train_err) * 1.2:
        print(f"\nâš ï¸  è­¦å‘Š: éªŒè¯é›†è¯¯å·®æ¯”è®­ç»ƒé›†é«˜20%ä»¥ä¸Šï¼")
        print(f"   è¿™å¯èƒ½å¯¼è‡´trainé™valä¸é™çš„é—®é¢˜ã€‚")
        print(f"   å»ºè®®:")
        print(f"   1. æ£€æŸ¥æ•°æ®åˆ’åˆ†æ˜¯å¦åˆç†ï¼ˆeasy/medium/difficultæ··åˆï¼‰")
        print(f"   2. å¢åŠ è®­ç»ƒé›†ä¸­çš„å›°éš¾æ ·æœ¬æ¯”ä¾‹")
        print(f"   3. ä½¿ç”¨è´¨é‡æ„ŸçŸ¥è®­ç»ƒï¼ˆ--photometric claheï¼‰")
    
    print(f"\n" + "="*60 + "\n")
    
    # æ˜¾ç¤ºå›¾åƒï¼ˆå¯é€‰ï¼‰
    try:
        plt.show()
    except:
        print("æ³¨æ„: æ— æ³•æ˜¾ç¤ºå›¾å½¢çª—å£ï¼ˆå¯èƒ½æ˜¯æ— GUIç¯å¢ƒï¼‰ï¼Œä½†å›¾åƒå·²ä¿å­˜ã€‚")

if __name__ == "__main__":
    main()

