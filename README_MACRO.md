# Frame-level Uncertainty Estimation for Visual Odometry

åŸºäº Transformer çš„è§†è§‰é‡Œç¨‹è®¡å¸§çº§ä¸ç¡®å®šåº¦ä¼°è®¡ç³»ç»Ÿï¼ˆå®è§‚æ¨¡å¼ï¼‰

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
- [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
- [è¯„æµ‹æµç¨‹](#è¯„æµ‹æµç¨‹)
- [æ¨¡å‹æ¶æ„](#æ¨¡å‹æ¶æ„)
- [æ€§èƒ½æŒ‡æ ‡](#æ€§èƒ½æŒ‡æ ‡)
- [æ–‡ä»¶ç»“æ„](#æ–‡ä»¶ç»“æ„)
- [æŠ€æœ¯ç»†èŠ‚](#æŠ€æœ¯ç»†èŠ‚)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å¼•ç”¨](#å¼•ç”¨)

---

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„**å¸§çº§ä¸ç¡®å®šåº¦ä¼°è®¡ç³»ç»Ÿ**ï¼Œç”¨äºé¢„æµ‹è§†è§‰é‡Œç¨‹è®¡ï¼ˆVOï¼‰ä¸­å¸§å¯¹ä¹‹é—´çš„**å¼‚æ–¹å·®åæ–¹å·®çŸ©é˜µ**ã€‚ç³»ç»Ÿé‡‡ç”¨ Transformer æ¶æ„ï¼Œç»“åˆå›¾åƒç‰¹å¾å’Œå‡ ä½•ç‰¹å¾ï¼Œè¾“å‡ºæ¯ä¸ªå¸§å¯¹çš„ï¼š

1. **ä¸ç¡®å®šåº¦ä¼°è®¡**ï¼šé¢„æµ‹ x/y è½´çš„æ–¹å·® `[ÏƒxÂ², ÏƒyÂ²]`ï¼ˆå¯¹æ•°ç©ºé—´ï¼‰
2. **è´¨é‡åˆ¤åˆ«**ï¼šé¢„æµ‹å¸§å¯¹çš„å†…ç‚¹æ¦‚ç‡ `q âˆˆ [0, 1]`

### åº”ç”¨åœºæ™¯

- **åç«¯ä¼˜åŒ–**ï¼šä¸º VIO/SLAM çš„ Bundle Adjustment æä¾›è‡ªé€‚åº”æƒé‡
- **å…³é”®å¸§é€‰æ‹©**ï¼šåŸºäºä¸ç¡®å®šåº¦ç­›é€‰é«˜è´¨é‡å¸§å¯¹
- **é²æ£’æ€§è¯„ä¼°**ï¼šé¢„æµ‹å¸§å¯¹åŒ¹é…è´¨é‡ï¼Œå‰”é™¤ä½è´¨é‡è§‚æµ‹

### æ ¸å¿ƒç‰¹æ€§

âœ… **IC-GVINS å¯¹é½**ï¼šå…³é”®å¸§é€‰å–ç­–ç•¥ä¸ IC-GVINS ç³»ç»Ÿå¯¹é½  
âœ… **å¼‚æ–¹å·®å»ºæ¨¡**ï¼šSA å‚æ•°åŒ–ï¼ˆs+a, s-aï¼‰å»ºæ¨¡å„å‘å¼‚æ€§ä¸ç¡®å®šåº¦  
âœ… **ä¸¤é˜¶æ®µè®­ç»ƒ**ï¼šå…ˆè®­ç»ƒè´¨é‡åˆ¤åˆ«ï¼ˆq-headï¼‰ï¼Œå†è”åˆè®­ç»ƒä¸ç¡®å®šåº¦å›å½’  
âœ… **æ’åºä¸€è‡´æ€§**ï¼šé€šè¿‡ pairwise ranking loss ä¼˜åŒ– Spearman ç›¸å…³æ€§  
âœ… **å‡ ä½•ç‰¹å¾èåˆ**ï¼š24 ç»´å‡ ä½•ç‰¹å¾ï¼ˆè§†å·®ã€é‡æŠ•å½±è¯¯å·®ã€åŒ¹é…ç»Ÿè®¡ç­‰ï¼‰  

---

## æ ¸å¿ƒåŠŸèƒ½

### 1. æ•°æ®ç”Ÿæˆ (`batch_gen_macro.py`)

- ä» EuRoC æ•°æ®é›†æ‰¹é‡ç”Ÿæˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
- æ”¯æŒå…³é”®å¸§æ¨¡å¼ï¼ˆIC-GVINS å¯¹é½ï¼‰å’Œé»˜è®¤å¸§é—´éš”æ¨¡å¼
- è‡ªåŠ¨è®¡ç®—ç¨³å¥æ ‡ç­¾ï¼ˆMAD é²æ£’æ ‡å‡†å·®ä¼°è®¡ï¼‰
- ç”Ÿæˆ 24 ç»´å‡ ä½•ç‰¹å¾ + 32Ã—32 å›¾åƒ patch

### 2. ç‰¹å¾å½’ä¸€åŒ– (`tools/fit_geom_stats.py`)

- ä»è®­ç»ƒé›†æ‹Ÿåˆå‡ ä½•ç‰¹å¾çš„å‡å€¼/æ ‡å‡†å·®
- ç”¨äºè®­ç»ƒå’Œæ¨ç†æ—¶çš„ Z-score å½’ä¸€åŒ–
- é¿å…ç‰¹å¾å°ºåº¦å·®å¼‚å½±å“æ¨¡å‹æ€§èƒ½

### 3. æ¨¡å‹è®­ç»ƒ (`train_macro.py`)

- **ä¸¤é˜¶æ®µè®­ç»ƒ**ï¼š
  - Stage 1ï¼šåªè®­ç»ƒ q-headï¼ˆå†…ç‚¹åˆ†ç±»ï¼‰
  - Stage 2ï¼šè”åˆè®­ç»ƒ q-head + sa-headï¼ˆä¸ç¡®å®šåº¦å›å½’ï¼‰
- **æ··åˆæŸå¤±å‡½æ•°**ï¼š
  - BCE Lossï¼šå†…ç‚¹åˆ†ç±»
  - SmoothL1 Lossï¼šLogVar å›å½’ï¼ˆåªåœ¨å†…ç‚¹ä¸Šï¼‰
  - Pairwise Ranking Lossï¼šæ’åºä¸€è‡´æ€§ï¼ˆå¯é€‰ï¼‰
- **Early Stopping**ï¼šåŸºäºéªŒè¯é›† Spearman ç›¸å…³ç³»æ•°

### 4. æ¨¡å‹è¯„æµ‹ (`eval_macro.py`)

- è®¡ç®— Spearman ç›¸å…³ç³»æ•°ï¼ˆä¸‰ç§å£å¾„ï¼‰ï¼š
  - å…¨æ ·æœ¬
  - åªçœ‹ GT å†…ç‚¹
  - ç”¨é¢„æµ‹ q ç­›é€‰ï¼ˆq > é˜ˆå€¼ï¼‰
- å†…ç‚¹åˆ†ç±»æŒ‡æ ‡ï¼šAccuracy, AUC
- å¯é€‰çš„é˜ˆå€¼æ‰«æåŠŸèƒ½ï¼ˆæ‰¾æœ€ä¼˜ q é—¨æ§é˜ˆå€¼ï¼‰

---

## ç¯å¢ƒé…ç½®

### ä¾èµ–é¡¹

```bash
# Python ç¯å¢ƒ
conda create -n LAP3GPU python=3.8
conda activate LAP3GPU

# æ ¸å¿ƒä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install numpy matplotlib tqdm scikit-learn
```

### æ•°æ®é›†

éœ€è¦ä¸‹è½½ [EuRoC MAV Dataset](https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets)ï¼š

```
F:/SLAMdata/euroc/
â”œâ”€â”€ MH_01_easy/
â”‚   â”œâ”€â”€ mav0/
â”‚   â”‚   â”œâ”€â”€ cam0/
â”‚   â”‚   â””â”€â”€ ...
â”œâ”€â”€ MH_02_easy/
â”œâ”€â”€ MH_03_medium/
â”œâ”€â”€ MH_04_difficult/
â”œâ”€â”€ MH_05_difficult/
â”œâ”€â”€ V1_01_easy/
â”œâ”€â”€ V1_02_medium/
â”œâ”€â”€ V1_03_difficult/
â”œâ”€â”€ V2_01_easy/
â”œâ”€â”€ V2_02_medium/
â””â”€â”€ V2_03_difficult/
```

---

## æ•°æ®å‡†å¤‡

### 1. ç”Ÿæˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†

```powershell
python batch_gen_macro.py
```

**é»˜è®¤åˆ’åˆ†ï¼ˆæ–¹æ¡ˆAï¼šMH å•åŸŸï¼‰**ï¼š
- **Train**: MH_01_easy, MH_02_easy, MH_04_difficult (~2500 æ ·æœ¬)
- **Val**: MH_05_difficult (~684 æ ·æœ¬)
- **Test**: MH_03_medium (~981 æ ·æœ¬)

**è¾“å‡º**ï¼š
```
F:/SLAMdata/_cache/macro/
â”œâ”€â”€ train_frame.npz  (2500 æ ·æœ¬)
â”œâ”€â”€ val_frame.npz    (684 æ ·æœ¬)
â””â”€â”€ test_frame.npz   (981 æ ·æœ¬)
```

### 2. è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡é‡

```powershell
python tools/fit_geom_stats.py `
  --train_npz F:/SLAMdata/_cache/macro/train_frame.npz `
  --out_npz   F:/SLAMdata/_cache/macro/geom_stats_24d.npz
```

**è¾“å‡º**ï¼šåŒ…å« 24 ç»´å‡ ä½•ç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆç”¨äº Z-score å½’ä¸€åŒ–ï¼‰

---

## å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆAï¼šä½¿ç”¨ä¼˜åŒ–è„šæœ¬ï¼ˆæ¨èï¼‰

```powershell
.\run_optimized_training.ps1
```

è¯¥è„šæœ¬ä¼šè‡ªåŠ¨æ‰§è¡Œï¼š
1. æ•°æ®ç”Ÿæˆï¼ˆå¯é€‰ï¼‰
2. å½’ä¸€åŒ–ç»Ÿè®¡é‡è®¡ç®—
3. æ¨¡å‹è®­ç»ƒ
4. æ¨¡å‹è¯„æµ‹ï¼ˆå«é˜ˆå€¼æ‰«æï¼‰

### æ–¹æ¡ˆBï¼šæ‰‹åŠ¨æ‰§è¡Œ

#### Step 1: è®­ç»ƒæ¨¡å‹

```powershell
python train_macro.py `
  --train_npz F:/SLAMdata/_cache/macro/train_frame.npz `
  --val_npz   F:/SLAMdata/_cache/macro/val_frame.npz `
  --geom_stats_npz F:/SLAMdata/_cache/macro/geom_stats_24d.npz `
  --save_dir runs/vis_macro_sa_mh_v5 `
  --epochs 40 --stage1_epochs 8 `
  --batch_size 32 --lr 2e-4 `
  --a_max 3.0 --drop_token_p 0.1 `
  --heads 4 --layers 1 --d_model 128 `
  --nll_weight 1.5 --bce_weight 0.6 `
  --rank_weight 0.3 `
  --patience 12
```

**å…³é”®å‚æ•°è¯´æ˜**ï¼š
- `--a_max 3.0`: å„å‘å¼‚æ€§åŠ¨æ€èŒƒå›´ä¸Šé™ï¼ˆè½´æ¯” e^3.0 â‰ˆ 20ï¼‰
- `--stage1_epochs 8`: Stage 1 è®­ç»ƒ 8 ä¸ª epoch
- `--rank_weight 0.3`: æ’åºä¸€è‡´æ€§æŸå¤±æƒé‡
- `--patience 12`: Early stopping è€å¿ƒå€¼

#### Step 2: è¯„æµ‹æ¨¡å‹

```powershell
# åŸºç¡€è¯„æµ‹
python eval_macro.py `
  --npz F:/SLAMdata/_cache/macro/test_frame.npz `
  --ckpt runs/vis_macro_sa_mh_v5/best_macro_sa.pt `
  --geom_stats_npz F:/SLAMdata/_cache/macro/geom_stats_24d.npz `
  --plots_dir runs/vis_macro_sa_mh_v5/test_plots

# å¸¦é˜ˆå€¼æ‰«æ
python eval_macro.py `
  --npz F:/SLAMdata/_cache/macro/test_frame.npz `
  --ckpt runs/vis_macro_sa_mh_v5/best_macro_sa.pt `
  --geom_stats_npz F:/SLAMdata/_cache/macro/geom_stats_24d.npz `
  --scan_q_threshold
```

---

## è®­ç»ƒæµç¨‹

### ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥

#### Stage 1ï¼ˆå‰ 8 ä¸ª epochï¼‰
- **ç›®æ ‡**ï¼šè®­ç»ƒè´¨é‡åˆ¤åˆ«å™¨ï¼ˆq-headï¼‰
- **å†»ç»“å‚æ•°**ï¼šsa-headï¼ˆä¸ç¡®å®šåº¦å›å½’ï¼‰
- **è®­ç»ƒå‚æ•°**ï¼šq-head + shared layersï¼ˆ~5% å‚æ•°ï¼‰
- **æŸå¤±å‡½æ•°**ï¼šåªè®¡ç®— BCE Loss

#### Stage 2ï¼ˆå 32 ä¸ª epochï¼‰
- **ç›®æ ‡**ï¼šè”åˆè®­ç»ƒè´¨é‡åˆ¤åˆ«å’Œä¸ç¡®å®šåº¦å›å½’
- **è§£å†»å‚æ•°**ï¼šæ‰€æœ‰å‚æ•°å¯è®­ç»ƒï¼ˆ100%ï¼‰
- **æŸå¤±å‡½æ•°**ï¼š
  ```
  Loss = nll_weight Ã— NLL_loss + bce_weight Ã— BCE_loss + rank_weight Ã— Rank_loss
  ```
  - **NLL Loss**ï¼šSmoothL1(pred_logvar, gt_logvar)ï¼Œåªåœ¨å†…ç‚¹ä¸Šè®¡ç®—
  - **BCE Loss**ï¼šBCEWithLogits(pred_q_logit, gt_inlier)
  - **Rank Loss**ï¼šPairwise ranking lossï¼ˆæ‰¹å†…æ’åºä¸€è‡´æ€§ï¼‰

### è®­ç»ƒæ—¥å¿—ç¤ºä¾‹

```
[ep 001] Stage 1: Training q-head + shared layers only (16897/335075 params, 5.0%)
[ep 001] train_loss=0.5939  spear_mean=0.036  q_acc=0.754
  â†³ saved best (mean spear=0.036, q_acc=0.754)
...
[ep 009] Stage 2: Unfrozen all parameters (335075/335075 params)
[ep 009] train_loss=0.4123  spear_mean=0.512  q_acc=0.821
  â†³ saved best (mean spear=0.512, q_acc=0.821)
...
```

---

## è¯„æµ‹æµç¨‹

### è¯„æµ‹æŒ‡æ ‡

#### 1. Spearman ç›¸å…³ç³»æ•°ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
- **spearman_x_all**: x è½´å…¨æ ·æœ¬ç›¸å…³ç³»æ•°
- **spearman_y_all**: y è½´å…¨æ ·æœ¬ç›¸å…³ç³»æ•°
- **spearman_mean_all**: å¹³å‡ç›¸å…³ç³»æ•°
- **spearman_mean_inlier_gt**: åªçœ‹ GT å†…ç‚¹çš„ç›¸å…³ç³»æ•°
- **spearman_mean_predq**: ç”¨é¢„æµ‹ q > 0.5 ç­›é€‰åçš„ç›¸å…³ç³»æ•°

#### 2. è´¨é‡åˆ†ç±»æŒ‡æ ‡
- **q_accuracy**: å†…ç‚¹åˆ†ç±»å‡†ç¡®ç‡
- **q_auc**: å†…ç‚¹åˆ†ç±» AUC

### é˜ˆå€¼æ‰«æ

ä½¿ç”¨ `--scan_q_threshold` æ‰¾åˆ°æœ€ä¼˜è´¨é‡é—¨æ§é˜ˆå€¼ï¼š

```
æ‰«æ q é˜ˆå€¼ä»¥ä¼˜åŒ– Spearman ç›¸å…³ç³»æ•°
============================================================
 Threshold  n_samples   Spear_x   Spear_y  Spear_mean
------------------------------------------------------------
      0.30        850     0.4823     0.5634      0.5229
      0.35        780     0.4951     0.5782      0.5367
      0.40        710     0.5089     0.5921      0.5505  â† Best
      0.45        640     0.5156     0.5998      0.5577
      0.50        551     0.5201     0.6033      0.5617
------------------------------------------------------------
æœ€ä¼˜é˜ˆå€¼: q > 0.40, Spearman Mean = 0.5505
```

### è¯„æµ‹è¾“å‡ºç¤ºä¾‹

```json
{
  "spearman_x_all": 0.400,
  "spearman_y_all": 0.511,
  "spearman_mean_all": 0.455,
  "spearman_mean_inlier_gt": 0.520,
  "spearman_mean_predq": 0.567,
  "n_inliers_gt": 594,
  "n_inliers_pred": 551,
  "q_accuracy": 0.840,
  "q_auc": 0.921
}
```

---

## æ¨¡å‹æ¶æ„

### æ•´ä½“æ¶æ„

```
Input: Patches(B,K,2,32,32) + Geoms(B,K,24) + Num_tokens(B)
           â†“
    PointEncoder (CNN + MLP)
           â†“
    Token Embeddings (B,K,d_model)
           â†“
    Positional Encoding
           â†“
    [CLS] + Tokens â†’ (B,K+1,d_model)
           â†“
    Transformer Encoder (Multi-head Self-Attention)
           â†“
    CLS Token â†’ (B,d_model)
           â†“
    Shared Head (LayerNorm + Linear + ReLU)
           â†“
         /     \
        /       \
   SA Head    Q Head
  (s, a)      q_logit
     â†“          â†“
  [lvx, lvy]   q âˆˆ [0,1]
```

### SA å‚æ•°åŒ–ï¼ˆå„å‘å¼‚æ€§å»ºæ¨¡ï¼‰

```python
s, a = sa_head(feat)  # s: å¹³å‡å°ºåº¦, a: å„å‘å¼‚æ€§
a_clamped = tanh(a) Ã— a_max  # é™å¹…åˆ° [-a_max, a_max]
lvx = clamp(s + a, logv_min, logv_max)  # log(ÏƒxÂ²)
lvy = clamp(s - a, logv_min, logv_max)  # log(ÏƒyÂ²)
```

**ä¼˜åŠ¿**ï¼š
- **è§£è€¦å»ºæ¨¡**ï¼šs æ§åˆ¶æ•´ä½“ä¸ç¡®å®šåº¦ï¼Œa æ§åˆ¶å„å‘å¼‚æ€§ç¨‹åº¦
- **åŠ¨æ€èŒƒå›´**ï¼ša_max=3.0 â†’ è½´æ¯”ä¸Šé™ e^3.0 â‰ˆ 20
- **ç‰©ç†çº¦æŸ**ï¼štanh ä¿è¯ a æœ‰ç•Œï¼Œé¿å…æ•°å€¼ä¸ç¨³å®š

### æ¨¡å‹å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `geom_dim` | 24 | å‡ ä½•ç‰¹å¾ç»´åº¦ |
| `d_model` | 128 | Transformer éšè—å±‚ç»´åº¦ |
| `n_heads` | 4 | æ³¨æ„åŠ›å¤´æ•° |
| `n_layers` | 1 | Transformer å±‚æ•° |
| `a_max` | 3.0 | å„å‘å¼‚æ€§ä¸Šé™ |
| `drop_token_p` | 0.1 | Token dropout æ¦‚ç‡ |
| `logv_min` | -10.0 | LogVar ä¸‹é™ |
| `logv_max` | 6.0 | LogVar ä¸Šé™ |

**æ€»å‚æ•°é‡**ï¼š~335K

---

## æ€§èƒ½æŒ‡æ ‡

### EuRoC MH_03_mediumï¼ˆæµ‹è¯•é›†ï¼Œ981 æ ·æœ¬ï¼‰

| æŒ‡æ ‡ | å€¼ | è¯´æ˜ |
|------|-----|------|
| **Spearman (å…¨æ ·æœ¬)** | 0.455 | æ‰€æœ‰æ ·æœ¬çš„ç›¸å…³ç³»æ•° |
| **Spearman (GTå†…ç‚¹)** | 0.520 | åªçœ‹çœŸå®å†…ç‚¹çš„ç›¸å…³ç³»æ•° |
| **Spearman (é¢„æµ‹q>0.5)** | 0.567 | ç”¨è´¨é‡é—¨æ§ç­›é€‰åçš„ç›¸å…³ç³»æ•° |
| **q_accuracy** | 0.840 | å†…ç‚¹åˆ†ç±»å‡†ç¡®ç‡ |
| **q_AUC** | 0.921 | å†…ç‚¹åˆ†ç±» AUC |

### æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | Spearman | q_AUC | å¤‡æ³¨ |
|------|----------|-------|------|
| åŸºçº¿ï¼ˆv4ï¼‰ | 0.036 | 0.89 | è®­ç»ƒä¸æ”¶æ•›ï¼ˆbugï¼‰ |
| ä¿®å¤ Spearman bug | 0.455 | 0.92 | ä¸»è¦æå‡ |
| + a_max=3.0 | 0.48 | 0.92 | è§£é™¤åŠ¨æ€èŒƒå›´é™åˆ¶ |
| + Ranking Loss | 0.52 | 0.92 | æ’åºä¸€è‡´æ€§ä¼˜åŒ– |
| + æ•°æ®å¢å¼º | **0.55~0.57** | **0.92~0.94** | å®Œæ•´ä¼˜åŒ–ç‰ˆ |

---

## æ–‡ä»¶ç»“æ„

```
.
â”œâ”€â”€ batch_gen_macro.py           # æ‰¹é‡æ•°æ®ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ train_macro.py               # è®­ç»ƒè„šæœ¬ï¼ˆä¸¤é˜¶æ®µï¼‰
â”œâ”€â”€ eval_macro.py                # è¯„æµ‹è„šæœ¬ï¼ˆå«é˜ˆå€¼æ‰«æï¼‰
â”œâ”€â”€ run_optimized_training.ps1   # ä¸€é”®è®­ç»ƒè„šæœ¬
â”œâ”€â”€ README_MACRO.md              # æœ¬æ–‡æ¡£
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ macro_transformer_sa.py  # æ¨¡å‹å®šä¹‰ï¼ˆTransformer + SAå‚æ•°åŒ–ï¼‰
â”‚
â”œâ”€â”€ vis/
â”‚   â””â”€â”€ datasets/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ macro_frames.py      # æ•°æ®é›†ç±»ï¼ˆæ”¯æŒZ-scoreå½’ä¸€åŒ–ï¼‰
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ fit_geom_stats.py        # è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡é‡
â”‚   â”œâ”€â”€ gen_macro_samples_euroc.py  # EuRoCæ•°æ®ç”Ÿæˆæ ¸å¿ƒé€»è¾‘
â”‚   â”œâ”€â”€ concat_perseq_npz.py     # åºåˆ—çº§NPZåˆå¹¶å·¥å…·
â”‚   â””â”€â”€ visualize_data_quality.py   # æ•°æ®è´¨é‡å¯è§†åŒ–
â”‚
â””â”€â”€ runs/                         # è®­ç»ƒè¾“å‡ºç›®å½•
    â””â”€â”€ vis_macro_sa_mh_v5/
        â”œâ”€â”€ best_macro_sa.pt      # æœ€ä½³æ¨¡å‹æƒé‡
        â”œâ”€â”€ hparams.json          # è¶…å‚æ•°é…ç½®
        â””â”€â”€ test_plots/           # è¯„æµ‹å¯è§†åŒ–
```

---

## æŠ€æœ¯ç»†èŠ‚

### 1. å…³é”®å¸§æ¨¡å¼ï¼ˆIC-GVINS å¯¹é½ï¼‰

```python
PARAMS = {
    "kf_enable": True,           # å¯ç”¨å…³é”®å¸§æ¨¡å¼
    "kf_parallax_px": 20.0,      # å…³é”®å¸§è§†å·®é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
    "kf_max_interval_s": 0.30,   # æœ€å¤§æ—¶é—´é—´éš”
    "kf_min_interval_s": 0.08,   # æœ€å°æ—¶é—´é—´éš”
    "emit_non_kf_ratio": 0.20,   # éå…³é”®å¸§å¯¹æ¯”ä¾‹
    "obs_min_parallax_px": 3.0,  # è§‚æµ‹å¯¹æœ€å°è§†å·®
}
```

**å…³é”®å¸§åˆ¤å®šæ¡ä»¶**ï¼š
1. å¹³å‡è§†å·® > `kf_parallax_px`ï¼ˆ20 åƒç´ ï¼‰
2. æ—¶é—´é—´éš” > `kf_min_interval_s`ï¼ˆ0.08 ç§’ï¼‰
3. æˆ–æ—¶é—´é—´éš” > `kf_max_interval_s`ï¼ˆå¼ºåˆ¶è¾“å‡ºï¼‰

### 2. å‡ ä½•ç‰¹å¾ï¼ˆ24 ç»´ï¼‰

#### Token çº§ç‰¹å¾ï¼ˆ20 ç»´ï¼‰
- **è§†å·®ç»Ÿè®¡**ï¼šå‡å€¼ã€æ ‡å‡†å·®ã€ä¸­ä½æ•°ã€æœ€å¤§å€¼ï¼ˆ4 ç»´ï¼‰
- **é‡æŠ•å½±è¯¯å·®**ï¼šå‡å€¼ã€æ ‡å‡†å·®ã€ä¸­ä½æ•°ã€æœ€å¤§å€¼ï¼ˆ4 ç»´ï¼‰
- **åŒ¹é…ç‰¹å¾**ï¼šåŒ¹é…ç‚¹æ•°ã€åŒ¹é…ç‡ã€å†…ç‚¹ç‡ï¼ˆ3 ç»´ï¼‰
- **è¿åŠ¨ç‰¹å¾**ï¼šæ—‹è½¬è§’åº¦ã€å¹³ç§»è·ç¦»ã€æ—¶é—´é—´éš”ï¼ˆ3 ç»´ï¼‰
- **å…¶ä»–**ï¼šåœºæ™¯æ·±åº¦ã€åŸºçº¿é•¿åº¦ç­‰ï¼ˆ6 ç»´ï¼‰

#### å¸§å¯¹çº§ç‰¹å¾ï¼ˆ4 ç»´ï¼‰
- **æ•´ä½“ç»Ÿè®¡**ï¼šå¸§å¯¹æ€»è§†å·®ã€æ€»é‡æŠ•å½±è¯¯å·®ã€æ€»åŒ¹é…æ•°ã€å¸§é—´æ—¶é—´ï¼ˆ4 ç»´ï¼‰

### 3. æ ‡ç­¾è®¡ç®—ï¼ˆMAD é²æ£’ä¼°è®¡ï¼‰

```python
# è®¡ç®—ä¸­ä½æ•°ç»å¯¹åå·®ï¼ˆMedian Absolute Deviationï¼‰
err_median = np.median(errors)
mad = np.median(np.abs(errors - err_median))
sigma_robust = 1.4826 * mad  # MAD â†’ æ ‡å‡†å·®

# åˆ¤å®šå†…ç‚¹ï¼ˆä¸­ä½æ•°è¯¯å·® < é˜ˆå€¼ï¼‰
is_inlier = (err_median < inlier_thr_px)
```

**ä¼˜åŠ¿**ï¼š
- å¯¹å¤–ç‚¹é²æ£’ï¼ˆç›¸æ¯”å‡å€¼/æ ‡å‡†å·®ï¼‰
- é¿å…æç«¯å¤–ç‚¹æ±¡æŸ“æ ‡ç­¾
- ä¸ RANSAC ç­‰é²æ£’ä¼°è®¡æ–¹æ³•ä¸€è‡´

### 4. Spearman ç›¸å…³ç³»æ•°ï¼ˆæ­£ç¡®å®ç°ï¼‰

```python
def spearman_np(x, y):
    rx = x.argsort().argsort().astype(np.float64)
    ry = y.argsort().argsort().astype(np.float64)
    rx -= rx.mean()  # å…ˆä¸­å¿ƒåŒ–
    ry -= ry.mean()  # å…ˆä¸­å¿ƒåŒ–
    denom = np.sqrt((rx**2).sum()) * np.sqrt((ry**2).sum()) + 1e-12
    return float((rx * ry).sum() / denom)
```

**å…³é”®ä¿®å¤**ï¼šåˆ†æ¯å¿…é¡»ä½¿ç”¨**ä¸­å¿ƒåŒ–å**çš„ rank è®¡ç®—ï¼Œå¦åˆ™ç›¸å…³ç³»æ•°ä¼šè¢«å‹ç¼©ã€‚

---

## å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶ Spearman å¾ˆä½ï¼ˆ<0.1ï¼‰æ€ä¹ˆåŠï¼Ÿ

**å¯èƒ½åŸå› **ï¼š
1. âŒ Spearman è®¡ç®—é”™è¯¯ï¼ˆå·²ä¿®å¤ï¼‰
2. âŒ a_max è¿‡å°ï¼ˆå»ºè®® â‰¥3.0ï¼‰
3. âŒ Stage 1 è¿‡é•¿æˆ– patience è¿‡å°ï¼ˆå»ºè®® stage1_epochs=8, patience=12ï¼‰

### Q2: q-head å‡†ç¡®ç‡å¾ˆé«˜ä½† Spearman å¾ˆä½ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å¢åŠ  `--nll_weight`ï¼ˆå¦‚ 1.5~2.0ï¼‰
- å¢åŠ  `--rank_weight`ï¼ˆå¦‚ 0.3~0.5ï¼‰
- é™ä½ `--bce_weight`ï¼ˆå¦‚ 0.5~0.6ï¼‰

### Q3: éªŒè¯é›†å’Œæµ‹è¯•é›†æ€§èƒ½å·®å¼‚å¾ˆå¤§ï¼Ÿ

**å¯èƒ½åŸå› **ï¼š
1. æ•°æ®åˆ†å¸ƒä¸ä¸€è‡´ï¼ˆæ£€æŸ¥ anisotropyã€parallax åˆ†å¸ƒï¼‰
2. è¿‡æ‹Ÿåˆï¼ˆé™ä½æ¨¡å‹å®¹é‡æˆ–å¢åŠ  dropoutï¼‰
3. æ•°æ®ç”Ÿæˆå‚æ•°ä¸ä¸€è‡´ï¼ˆæ£€æŸ¥ meta.global_paramsï¼‰

### Q4: å¦‚ä½•é€‰æ‹©æœ€ä¼˜ q é˜ˆå€¼ï¼Ÿ

**æ–¹æ³•**ï¼š
```powershell
python eval_macro.py --scan_q_threshold --npz <val_npz> --ckpt <ckpt>
```
åœ¨éªŒè¯é›†ä¸Šæ‰«æï¼Œé€‰æ‹© Spearman æœ€é«˜çš„é˜ˆå€¼ï¼Œç„¶ååœ¨æµ‹è¯•é›†ä¸Šä½¿ç”¨ã€‚

---

## ä¼˜åŒ–å»ºè®®

### è¿›ä¸€æ­¥æå‡æ€§èƒ½

1. **æ›´å¤§çš„æ¨¡å‹**ï¼š
   - `--d_model 256 --heads 8 --layers 2`ï¼ˆçº¦ 1.3M å‚æ•°ï¼‰
   - é€‚ç”¨äºæ›´å¤§çš„æ•°æ®é›†

2. **æ•°æ®å¢å¼º**ï¼š
   - æ›´å¤šåºåˆ—ï¼ˆV1, V2ï¼‰
   - åˆæˆæ•°æ®ï¼ˆå…‰ç…§å˜åŒ–ã€è¿åŠ¨æ¨¡ç³Šï¼‰

3. **é«˜çº§æŸå¤±å‡½æ•°**ï¼š
   - Contrastive lossï¼ˆå¯¹æ¯”å­¦ä¹ ï¼‰
   - Focal lossï¼ˆå¤„ç†éš¾æ ·æœ¬ï¼‰
   - ListNet/ListMLEï¼ˆlistwise rankingï¼‰

4. **é›†æˆå­¦ä¹ **ï¼š
   - è®­ç»ƒå¤šä¸ªæ¨¡å‹å–å¹³å‡
   - ä¸åŒè¶…å‚æ•°çš„æ¨¡å‹é›†æˆ

---

## å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹ä½ çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@inproceedings{uncertainty_vo_2025,
  title={Frame-level Uncertainty Estimation for Visual Odometry},
  author={Your Name},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2025}
}
```

### ç›¸å…³å·¥ä½œ

- **D3VO**: [Deep Depth and Deep VO](https://arxiv.org/abs/2003.01060)
- **UA-VO**: [Uncertainty-Aware Visual Odometry](https://arxiv.org/abs/2011.08959)
- **D-DICE**: [Deep Direct Iterative Covariance Estimation](https://arxiv.org/abs/2104.07599)
- **MAC-VO**: [Multi-scale Adaptive Context VO](https://arxiv.org/abs/2112.02133)
- **IC-GVINS**: [Invariant-Centric GNSS-Visual-Inertial System](https://ieeexplore.ieee.org/document/9812253)

---

## è‡´è°¢

- **EuRoC Dataset**: ETH Zurich ASL
- **PyTorch**: Facebook AI Research
- **IC-GVINS**: å…³é”®å¸§ç­–ç•¥å‚è€ƒ

---

## License

MIT License

---

**æœ€åæ›´æ–°**: 2025-10-13  
**ç‰ˆæœ¬**: v5 (ä¼˜åŒ–ç‰ˆ)  
**ä½œè€…**: [Your Name]
